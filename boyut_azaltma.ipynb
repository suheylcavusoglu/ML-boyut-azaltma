{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ders: Büyük Veri Setleri Üzerinde Veri Madenciliği\n",
    "## Vize Sınavı Projesi\n",
    "\n",
    "- Yazar: Süheyl ÇAVUŞOĞLU\n",
    "\n",
    "\n",
    "Bu proje kapsamında; özellik seçimine bağlı temel boyut indirme yöntemlerinin (Missing Values, Single Unique Values, Collinear Features, Zero Importance Features, Low Importance Features) bir sınıflandırıcı başarısını nasıl etkilediği araştırılacaktır.\n",
    "Yapılacaklar:\n",
    "- Sınıflandırma maksadıyla çok boyutlu bir dataset (d>10) bulun.\n",
    "- Bu dataset üzerinde 2 sınıflandırıcı başarısını elde edin.\n",
    "- Github reposunda (https://github.com/WillKoehrsen/feature-selector) verilen özellik seçme yaklaşımları ile datasette boyut indirgeme gerçekleyin.\n",
    "- Yeniden aynı sınıflandırıcıların başarısını test edin.\n",
    "- Kodları ve raporu edestek5’e yükleyin. Rapor IEEE formatında özet, giriş, yöntem, örnek sonuçlar ve kaynakça bölümünden oluşmalıdır.\n",
    "\n",
    "\n",
    "Not: Kodlar, benzerlik programından geçirildikten sonra değerlendirilecektir. İçeriğinizin başkası ile birebir aynı veya benzer olması durumunda değerlendirmeye alınmayacaktır. Python haricinde başka bir dilde gerçekleme yapacaklar da aynı adımları işletmelidir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kullanılan Veri Setinin Linki: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "Input variables:\n",
    "#### bank client data:\n",
    "- 1 - age (numeric)\n",
    "- 2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "- 3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "- 4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "- 5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "- 6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "- 7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "#### related with the last contact of the current campaign:\n",
    "- 8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "- 9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "- 10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "- 11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known.Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "#### other attributes:\n",
    "- 12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "- 13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "- 14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "- 15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "#### social and economic context attributes:\n",
    "- 16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "- 17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "- 18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "- 19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "- 20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # veri setimizi dataframe olarak okuyup üzerinde analizler yapabilmek için pandas'ı kullanacağım.\n",
    "import numpy as np # veri seti üzerinde yapılacak manipülasyonlar için kullanacağım.\n",
    "from sklearn.model_selection import train_test_split # modeli eğitirken train-test olarak ayırırken kullanacağım.\n",
    "from sklearn.metrics import accuracy_score # model başarılarını ölçerken kullanacağım.\n",
    "from sklearn.linear_model import LogisticRegression # veri seti üzerinde Logistic Regression modeli kurarken kullanacağım.\n",
    "from sklearn.ensemble import RandomForestClassifier # veri seti üzerinde Random Forest modeli kurarken kullanacağım.\n",
    "from sklearn.preprocessing import LabelEncoder # veri setindeki kategorik değişkenleri sayısal değişkenlere çevirmek için kullanacağım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bank-additional-full.csv\", sep = \";\") # veri setini okudum.\n",
    "df.head() # veri setinin ilk 5 satırını gözlemledim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "duration          0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # veri setindeki eksik değerleri kontrol ettim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "job                object\n",
       "marital            object\n",
       "education          object\n",
       "default            object\n",
       "housing            object\n",
       "loan               object\n",
       "contact            object\n",
       "month              object\n",
       "day_of_week        object\n",
       "duration            int64\n",
       "campaign            int64\n",
       "pdays               int64\n",
       "previous            int64\n",
       "poutcome           object\n",
       "emp.var.rate      float64\n",
       "cons.price.idx    float64\n",
       "cons.conf.idx     float64\n",
       "euribor3m         float64\n",
       "nr.employed       float64\n",
       "y                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #kolonların veri tiplerini inceledim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'job' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['housemaid' 'services' 'admin.' 'blue-collar' 'technician' 'retired'\n",
      " 'management' 'unemployed' 'self-employed' 'unknown' 'entrepreneur'\n",
      " 'student']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'marital' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['married' 'single' 'divorced' 'unknown']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'education' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['basic.4y' 'high.school' 'basic.6y' 'basic.9y' 'professional.course'\n",
      " 'unknown' 'university.degree' 'illiterate']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'default' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['no' 'unknown' 'yes']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'housing' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['no' 'yes' 'unknown']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'loan' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['no' 'yes' 'unknown']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'contact' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['telephone' 'cellular']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'month' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'mar' 'apr' 'sep']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'day_of_week' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['mon' 'tue' 'wed' 'thu' 'fri']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'poutcome' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['nonexistent' 'failure' 'success']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'y' kolonunda yer alan tüm unique değerler:\n",
      "\n",
      " ['no' 'yes']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# kolonlarda veri tipi 'object' olanları sayısal değişkenlere çevireceğim. Bunun için öncelikle hangi kolonların object tipinde olduğunu görmek ve bu kolonlardaki her bir unique değeri yazdırmak için aşağıdaki for loop'undan yararlandım.\n",
    "\n",
    "object_columns_list = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for i in object_columns_list:\n",
    "    print(\"\\n'{}' kolonunda yer alan tüm unique değerler:\\n\\n\".format(i), df[i].unique())\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admin.': 0,\n",
       " 'blue-collar': 1,\n",
       " 'entrepreneur': 2,\n",
       " 'housemaid': 3,\n",
       " 'management': 4,\n",
       " 'retired': 5,\n",
       " 'self-employed': 6,\n",
       " 'services': 7,\n",
       " 'student': 8,\n",
       " 'technician': 9,\n",
       " 'unemployed': 10,\n",
       " 'unknown': 11}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verileri modelde okuyabilmek için kategorik değişkenleri encode ederek sayısal değişkenler haline getirmem gerekti.\n",
    "# encoding yöntemlerinden label encoder ve one-hot encoder arasından label encoder'ı seçtim çünkü bazı kolonların nominal olarak değil de ordinal olarak değerlendirilmesi gerektiğini düşünüyorum.\n",
    "# ayrıca label encoding, one-hot encoding'e göre daha hızlı ve daha az yer kaplamakta.\n",
    "\n",
    "# veri setindeki ilk object tipindeki kolona örnek olması için label encoder uyguladım. LabelEncoder sınıfı ile 'job' kolonunda yer alan unique değerleri alfabetik olarak sıralayıp 0'dan başlayarak numaralandırdım.\n",
    "label_encoder_job = LabelEncoder()\n",
    "df['job'] = label_encoder_job.fit_transform(df['job'])\n",
    "# numaralandırma yaptıktan sonra da hangi unique değere hangi sayının atandığını aşağıdaki şekilde yazdırdım.\n",
    "category_mapping = dict(zip(label_encoder_job.classes_, label_encoder_job.transform(label_encoder_job.classes_)))\n",
    "category_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  0,  1,  9,  5,  4, 10,  6, 11,  2,  8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job.unique() # job kolonunda yer alan unique değerler alfabetik sıralanmadığında da şu şekilde görünüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job kolonundaki encode işleminde bir sorun olmadığını gördükten sonra 'object' tipindeki tüm kolonlara da label encoding uyguladım.\n",
    "label_encoder = LabelEncoder()\n",
    "object_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "df[object_columns] = df[object_columns].apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri setindeki tüm kolonlar modele uygun duruma getirildi. Şimdi bağımsız (features --> X) değişkenler ile  bağımlı değişkeni (y) ayıracağım.\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # bağımsız değişkenler ile bağımlı değişkeni, train - test olarak ayırdım. \n",
    "#Veri setinin %80' ini eğitim seti olarak %20' sini de test olarak ayırdım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suheyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# veri setini train - test olarak da ayırdıktan sonra artık bir sınıflandırma modeli kurabiliriz. İlk modeli Lojistik Regresyon olarak belirledim.\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=320)  # maks iterasyonu 320'den büyük yaptığımda model başarısı düşmeye başladığı için 320'de bıraktım.\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "\n",
    "print(\"Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.91442097596504\n"
     ]
    }
   ],
   "source": [
    "# ödevde 2 tane farklı sınıflandırıcı modeli kurulması istendiği için şimdi 2. modeli kurabiliriz. İkinci model olarak da Random Forest algoritmasını belirledim.\n",
    "\n",
    "rand_for = RandomForestClassifier()\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred_rand_for = rand_for.predict(X_test)\n",
    "accuracy_rand_for = accuracy_score(y_test, y_pred_rand_for)\n",
    "print(\"Random Forest Accuracy: \", accuracy_rand_for)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lojistik regresyon ile yaptığım denemede model başarısını %91.15, random forest ile de %91.44 buldum. Şimdi boyut azaltma yöntemlerinden, Low Importance Features yöntemini uygulayarak model başarısını kontrol edeceğim ve bu yöntemin model başarısı üzerindeki etkisini gözlemleyeceğim."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Importance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb # lightgbm kütüphanesi içerisinde feature importance'ı belirleyebileceğimiz fonksiyonlar mevcut dolayısıyla bunları kullanabiliriz.\n",
    "\n",
    "model = lgb.LGBMClassifier() # LGBMClassifier sınıfını çağırdım.\n",
    "model.fit(X_train, y_train) # bağımsız değişkenlerimin ve bağımlı değişkenimin train olarak ayırdığım kısmını LGBMClassifier ile fit ettim.\n",
    "\n",
    "feature_importances = model.feature_importances_ # fit işlemi sonrasında model kurmuş oldum ve bu model sayesinde de bağımsız değişkenlerimin ne kadar önemli olduğunu saptayabildim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_threshold = np.percentile(feature_importances, 25)  # model için önemli olan bağımsız değişkenler (kolonlar) için bir sınır değeri (yüzde 25) belirledim.\n",
    "# Bu sınır değerden yüksek önem değerine sahip olan kolonları seçip modelde kullanacağım ve sonra da model başarısına nasıl yansıdığını gözlemleyeceğim.\n",
    "\n",
    "selected_features = X.columns[feature_importances > importance_threshold] # belirlediğim sınır değerden yüksek olan kolonları seçtim.\n",
    "X_train_reduced = X_train[selected_features] # düşük öneme sahip kolonları çıkarttıktan sonraki bağımsız değişken train seti\n",
    "X_test_reduced = X_test[selected_features] # düşük öneme sahip kolonları çıkarttıktan sonraki bağımsız değişken test seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Importance Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır:  Index(['default', 'loan', 'contact', 'poutcome', 'nr.employed'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "removed_features = X.columns[feature_importances <= importance_threshold]  # çıkarılan kolonların hangileri olduğunu kontrol ettim.\n",
    "print(\"Low Importance Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır: \", removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n",
      "Low Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy):  0.9084729303228939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suheyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_reduced = LogisticRegression(max_iter=320) # low importance features ile boyut azaltma işleminden sonra lojistik regresyon modelini tekrar kurdum (maks iterasyon sayısını ilk model ile aynı aldım).\n",
    "log_reg_reduced.fit(X_train_reduced, y_train)\n",
    "y_pred_log_reg_reduced = log_reg_reduced.predict(X_test_reduced)\n",
    "accuracy_log_reg_reduced = accuracy_score(y_test, y_pred_log_reg_reduced)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Low Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg)\n",
    "print(\"Low Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy):  0.91442097596504\n",
      "Low Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy):  0.9153920854576354\n"
     ]
    }
   ],
   "source": [
    "rand_for_reduced = RandomForestClassifier() # low importance features ile boyut azaltma işleminden sonra random forest modelini tekrar kurdum.\n",
    "rand_for_reduced.fit(X_train_reduced, y_train)\n",
    "y_pred_rand_for_reduced = rand_for_reduced.predict(X_test_reduced)\n",
    "accuracy_rand_for_reduced = accuracy_score(y_test, y_pred_rand_for_reduced)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Low Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for)\n",
    "print(\"Low Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Importance Features boyut azaltma yöntemini uyguladıktan sonra Lojistik Regresyon'da model başarısının bir miktar azaldığını, Random Forest'da başarının bir miktar arttığını gördüm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi de farklı bir boyut azaltma yöntemi olan Zero Importance Features yöntemini deneyip model başarılarını kontrol edeceğim. Bu yöntemde, bir modelin eğitimi sırasında herhangi bir özellik önemine sahip olmayan özellikler veri kümesinden çıkarılır. Bu özelliklerin çıkarılması, modelin karmaşıklığını azaltmaya ve performansını iyileştirmeye yardımcı olabilir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Importance Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low importance values yönteminde olduğu gibi Zero Importance Values yönteminde de lightgbm kütüphanesinden faydalanabiliriz.\n",
    "# lightgbm kütüphanesini kullanarak LGBMClassifier sınıfını çağırdım ve modeli fit ettim.\n",
    "model_zero = lgb.LGBMClassifier()\n",
    "model_zero.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = model_zero.feature_importances_ # veri setimdeki kolonların önemini belirledim.\n",
    "\n",
    "zero_importance_features_indices = np.where(feature_importances == 0)[0] \n",
    "zero_importance_features = X.columns[zero_importance_features_indices]\n",
    "# önem değeri 0 olan yani önemsiz olarak seçilebilecek kolonları seçtim.\n",
    "\n",
    "X_zero_importance_reduced = X.drop(zero_importance_features, axis=1) # önemsiz kolonları orijinal veri setimden çıkardım.\n",
    "\n",
    "X_train_zero_importance, X_test_zero_importance, y_train_zero_importance, y_test_zero_importance = train_test_split(X_zero_importance_reduced, y, test_size=0.2, random_state=42) \n",
    "# hazırladığım veri setinde modelleri kurmak için train - test ayrımı yaptım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n",
      "Zero Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suheyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali ile lojistij regresyon modeli kurdum ve maksimum iterasyonu yine orijinal veri seti üzerinde yaptığım modeldeki gibi (320) aldım.\n",
    "log_reg_zero_importance = LogisticRegression(max_iter=320)\n",
    "log_reg_zero_importance.fit(X_train_zero_importance, y_train_zero_importance)\n",
    "y_pred_log_reg_zero_importance = log_reg_zero_importance.predict(X_test_zero_importance)\n",
    "accuracy_log_reg_zero_importance = accuracy_score(y_test_zero_importance, y_pred_log_reg_zero_importance)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Zero Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg)\n",
    "print(\"Zero Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg_zero_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy):  0.91442097596504\n",
      "Zero Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy):  0.9142995872784656\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali ile random forest modeli kurdum.\n",
    "rand_for_zero_importance = RandomForestClassifier()\n",
    "rand_for_zero_importance.fit(X_train_zero_importance, y_train_zero_importance)\n",
    "y_pred_rand_for_zero_importance = rand_for_zero_importance.predict(X_test_zero_importance)\n",
    "accuracy_rand_for_zero_importance = accuracy_score(y_test_zero_importance, y_pred_rand_for_zero_importance)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Zero Importance Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for)\n",
    "print(\"Zero Importance Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for_zero_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Importance Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero Importance Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır: \", zero_importance_features) # hiç kolon çıkarılmamış?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_zero_importance_reduced.columns) # kolon sayısı hala 20?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Importance Features yöntemi ile boyut azaltıp modeli tekrar çalıştırdım ancak model sonuçlarının değişmediğini gördüm. Daha sonra Zero Importance Features yöntemi ile hangi kolonların çıkarıldığını inceledğimde ise aslında hiç kolon çıkarılmamış olduğunu gördüm. Yani veri setimdeki tüm kolonların model başarısında etkisi varmış. feature_importances_ değeri 0 olan hiçbir kolon olmadığını fark ettim. \n",
    "\n",
    "NOT: Zero Importance Features yöntemi ile boyut azaltmadan önceki ve azalttıktan sonraki Lojistik regresyon model başarıları hep aynı çıkıyor ancak Random Forest'ta Zero Importance Features yöntemi uygulandıktan sonraki sonuçlar, modeli her çalıştırdığımda değişiyor.\n",
    "Aslında tüm modelleri kurarken random_state'i aynı aldım ancak Zero Importance Features uygulaması sırasında Random Forest algoritmasındaki random_state parametresinde bazı bozukluklar olabileceği kanaatindeyim. Çünkü random forest algoritmasının boyut azaltmadan önceki versiyonunda da herhangi bir değişiklik olmuyor yani randon_state parametresi çalışıyor gibi görünüyor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi de farklı bir boyut azaltma yöntemi olan Collinear Features yöntemini deneyip model başarılarını kontrol edeceğim."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collinear Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collinear Features yöntemindeki amaç birbiri ile yüksek korelasyona sahip kolonları belirleyip bu kolonlardan bazılarını çıkartabilmektir. \n",
    "# Bu sayede kolon sayısı azaltilabilecektir ayrıca çıkartılan kolona yüksek derecede benzeyen kolonlar modelde kullanılacağı için, kolon çıkartmak model başarısını minimum seviyede etkileyecektir.\n",
    "\n",
    "correlation_matrix = X.corr() # ilk olarak bağımsız değişkenlerimin (features) birbirleri arasındaki korelasyonları belirledim.\n",
    "\n",
    "correlation_threshold = 0.8 # birbirleriyle yüksek korelasyona sahip kolonları belirlemek için sınır değerimi % 80 olarak belirledim. Bu sınırı %80 seçmemin sebebi birbiri ile düşük korelasyona sahip kolonları modelden çıkartmamaya özen göstermektir. \n",
    "# Ayrıca %80'den fazla bir benzerlik ararsam da gereksiz kolonların modelde kalmasına sebep olabilir, hesaplama süresini uzatabilir ve hatta overfitting'e sebep olabilirim.\n",
    "\n",
    "collinear_features = set() # veri setinden çıkartılacak kolonlar için boş bir küme hazırladım. kolonları seçip bu kümeye aktaracağım.\n",
    "\n",
    "# şimdi hazırladığım korelasyon matrisi üzerinde gezip hangi satır ve sütunda 0.8'den büyük değerler var onları bulmalıyım. \n",
    "# 0.8'den büyük olan değere sahip kolonları seçip collinear_features isimli boş kümede bu kolonları toplayacağım ki daha sonra üzerinde işlemler yapabileyim, mesela orijinal veri setimden çıkartabileyim.\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)): # kolon sayısı kadar bir aralıkta geziyorum.\n",
    "    for j in range(i): # gezdiğim sütun kadar satırda da gezmem gerekiyor. dolayısıyla üst satırın range'inde tekrar gezdim ki matristeki her bir hücreye (i,j) (örneğin 2,3 ya da 12,11 gibi) ulaşabileyim.\n",
    "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold: # gezdiğim hücreler arasında negatif değerler de olabilir ama benim aradığım korelasyonda negatif veya pozitif olmasının bir önemi yok bu yüzden bu değerleri mutlak değer içerisinde (abs) gözlemledim.\n",
    "                                                                       # aradığım şey korelasyonun %80'den büyük olması. pozitif veya negatif korelasyon olabilir.\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            collinear_features.add(colname)  # %80'den büyük korelasyona sahip olan kolonları collinear_features isimli kümeme ekledim.\n",
    "\n",
    "X_collinear_reduced = X.drop(collinear_features, axis=1) # yüksek korelasyona sahip kümeleri orijinal veri setimden çıkardım.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_collinear_reduced, y, test_size=0.2, random_state=42) # veri setimin son hali ile modellerimi kurmak için train-test ayrımımı yaptım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collinear Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır:  {'nr.employed', 'euribor3m'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Collinear Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır: \", collinear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collinear Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n",
      "Collinear Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy):  0.9071376547705754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suheyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali için lojistik regresyon modeli kurdum ve çalıştırdım.\n",
    "log_reg_collinear = LogisticRegression(max_iter=320)\n",
    "log_reg_collinear.fit(X_train, y_train)\n",
    "y_pred_log_reg_collinear = log_reg_collinear.predict(X_test)\n",
    "accuracy_log_reg_collinear = accuracy_score(y_test, y_pred_log_reg_collinear)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Collinear Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg)\n",
    "print(\"Collinear Features Yöntemi İle Boyut Azaltmadan SONRAKİ Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg_collinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collinear Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy):  0.91442097596504\n",
      "Collinear Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy):  0.9142995872784656\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali için random forest modeli kurdum ve çalıştırdım.\n",
    "rand_for_collinear = RandomForestClassifier()\n",
    "rand_for_collinear.fit(X_train, y_train)\n",
    "y_pred_rand_for_collinear = rand_for_collinear.predict(X_test)\n",
    "accuracy_rand_for_collinear = accuracy_score(y_test, y_pred_rand_for_collinear)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"Collinear Features Yöntemi İle Boyut Azaltmadan ÖNCEKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for)\n",
    "print(\"Collinear Features Yöntemi İle Boyut Azaltmadan SONRAKİ Random Forest Başarısı (Accuracy): \", accuracy_rand_for_collinear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collinear Features boyut azaltma yöntemini uyguladıktan sonra hem Lojistik Regresyon'da hem de Random Forest'da başarı oranının bir miktar azaldığını gördüm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi de bu veri setine uygulanabilen Low Importance Features ve Collinear Features yöntemlerini sırasıyla uygulayıp tekrar modelleri run edeceğim. İki yöntemi uyguladıktan sonraki model başarısını kontrol edeceğim."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Importance Features + Collinear Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lgb.LGBMClassifier() # LGBMClassifier sınıfını çağırdım.\n",
    "model_2.fit(X_train, y_train) # bağımsız değişkenlerimin ve bağımlı değişkenimin train olarak ayırdığım kısmını LGBMClassifier ile fit ettim.\n",
    "\n",
    "feature_importances_2 = model_2.feature_importances_ # fit işlemi sonrasında model kurmuş oldum ve bu model sayesinde de bağımsız değişkenlerimin ne kadar önemli olduğunu saptayabildim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_threshold_2 = np.percentile(feature_importances_2, 25)  # model için önemli olan bağımsız değişkenler (kolonlar) için bir sınır değeri (yüzde 25) belirledim.\n",
    "# Bu sınır değerden yüksek önem değerine sahip olan kolonları seçip modelde kullanacağım ve sonra da model başarısına nasıl yansıdığını gözlemleyeceğim.\n",
    "\n",
    "selected_features_2 = X.columns[feature_importances_2 > importance_threshold_2] # belirlediğim sınır değerden yüksek olan kolonları seçtim.\n",
    "X_train_reduced = X_train[selected_features_2] # düşük öneme sahip kolonları çıkarttıktan sonraki bağımsız değişken train seti\n",
    "X_test_reduced = X_test[selected_features_2] # düşük öneme sahip kolonları çıkarttıktan sonraki bağımsız değişken test seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32950, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape # bağımsız değişken sayısı 15'e düşmüş oldu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8238, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X.drop(['default', 'loan', 'contact', 'poutcome', 'nr.employed'], axis=1) # low importance features yönteminden sonra çıkartılacak kolonları orijinal veri setinden çıkarttım. Bu sayede Collinear Features yöntemini veri setinin son haline uygulayabilirim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  housing  month  day_of_week  duration  \\\n",
       "0   56    3        1          0        0      6            1       261   \n",
       "1   57    7        1          3        0      6            1       149   \n",
       "2   37    7        1          3        2      6            1       226   \n",
       "3   40    0        1          1        0      6            1       151   \n",
       "4   56    7        1          3        0      6            1       307   \n",
       "\n",
       "   campaign  pdays  previous  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0         1    999         0           1.1          93.994          -36.4   \n",
       "1         1    999         0           1.1          93.994          -36.4   \n",
       "2         1    999         0           1.1          93.994          -36.4   \n",
       "3         1    999         0           1.1          93.994          -36.4   \n",
       "4         1    999         0           1.1          93.994          -36.4   \n",
       "\n",
       "   euribor3m  \n",
       "0      4.857  \n",
       "1      4.857  \n",
       "2      4.857  \n",
       "3      4.857  \n",
       "4      4.857  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.head() # Low importance features yöntemini uyguladıktan sonra veri seti bu hale gelmiş oldu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_2 = X_reduced.corr() # ilk olarak bağımsız değişkenlerimin (features) birbirleri arasındaki korelasyonları belirledim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_threshold_2 = 0.8\n",
    "collinear_features_2 = set() # veri setinden çıkartılacak kolonlar için boş bir küme hazırladım. kolonları seçip bu kümeye aktaracağım.\n",
    "\n",
    "# şimdi hazırladığım korelasyon matrisi üzerinde gezip hangi satır ve sütunda 0.8'den büyük değerler var onları bulmalıyım. \n",
    "# 0.8'den büyük olan değere sahip kolonları seçip collinear_features isimli boş kümede bu kolonları toplayacağım ki daha sonra üzerinde işlemler yapabileyim, mesela orijinal veri setimden çıkartabileyim.\n",
    "\n",
    "for i in range(len(correlation_matrix_2.columns)): # kolon sayısı kadar bir aralıkta geziyorum.\n",
    "    for j in range(i): # gezdiğim sütun kadar satırda da gezmem gerekiyor. dolayısıyla üst satırın range'inde tekrar gezdim ki matristeki her bir hücreye (i,j) (örneğin 2,3 ya da 12,11 gibi) ulaşabileyim.\n",
    "        if abs(correlation_matrix_2.iloc[i, j]) > correlation_threshold_2: # gezdiğim hücreler arasında negatif değerler de olabilir ama benim aradığım korelasyonda negatif veya pozitif olmasının bir önemi yok bu yüzden bu değerleri mutlak değer içerisinde (abs) gözlemledim.\n",
    "                                                                       # aradığım şey korelasyonun %80'den büyük olması. pozitif veya negatif korelasyon olabilir.\n",
    "            colname = correlation_matrix_2.columns[i]\n",
    "            collinear_features_2.add(colname)  # %80'den büyük korelasyona sahip olan kolonları collinear_features isimli kümeme ekledim.\n",
    "\n",
    "X_collinear_reduced_2 = X_reduced.drop(collinear_features_2, axis=1) # yüksek korelasyona sahip kümeleri orijinal veri setimden çıkardım.\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_collinear_reduced_2, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collinear Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır:  {'euribor3m'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Collinear Features Yöntemi Uygulandıktan Sonra Çıkarılan Özellikler (kolonlar) şunlardır: \", collinear_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İlk Logistic Regression Başarısı (Accuracy):  0.9115076474872542\n",
      "Son Logistic Regression Başarısı (Accuracy):  0.9062879339645545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suheyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali için lojistik regresyon modeli kurdum ve çalıştırdım.\n",
    "log_reg_last = LogisticRegression(max_iter=320)\n",
    "log_reg_last.fit(X_train_reduced, y_train)\n",
    "y_pred_log_reg_last = log_reg_last.predict(X_test_reduced)\n",
    "accuracy_log_reg_last = accuracy_score(y_test, y_pred_log_reg_last)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"İlk Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg)\n",
    "print(\"Son Logistic Regression Başarısı (Accuracy): \", accuracy_log_reg_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İlk Random Forest Başarısı (Accuracy):  0.91442097596504\n",
      "Son Random Forest Başarısı (Accuracy):  0.9113862588006798\n"
     ]
    }
   ],
   "source": [
    "# veri setimin son hali için random forest modeli kurdum ve çalıştırdım.\n",
    "rand_for_last = RandomForestClassifier()\n",
    "rand_for_last.fit(X_train_reduced, y_train)\n",
    "y_pred_rand_for_last = rand_for_last.predict(X_test_reduced)\n",
    "accuracy_rand_for_last = accuracy_score(y_test, y_pred_rand_for_last)\n",
    "\n",
    "# boyut azaltmadan önceki ve sonraki model başarılarını ekrana yazdırdım.\n",
    "print(\"İlk Random Forest Başarısı (Accuracy): \", accuracy_rand_for)\n",
    "print(\"Son Random Forest Başarısı (Accuracy): \", accuracy_rand_for_last)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SONUÇ\n",
    "\n",
    "- Orijinal veri seti üzerinde Lojistik Regresyon ve Random Forest algoritmalarını çalıştırdım ve model başarılarını gözlemledim.\n",
    "- Veri seti üzerinde Missing Values, Single Unique Values, Collinear Features, Zero Importance Features, Low Importance Features yöntemlerinden Collinear Features, Zero Importance Features, Low Importance Features boyut azaltma yöntemlerini uyguladım.\n",
    "- Boyut azaltma yöntemlerini uyguladıktan sonra yeni veri setleri üzerinde tekrar Lojistik Regresyon ve Random Forest algoritmalarını çalıştırdım ve model başarılarındaki değişiklikleri gözlemledim.\n",
    "- Zero Importance Features boyut azaltma yöntemini uygulayıp model başarılarını karşılaştırdığımda bu yöntem ile aslında hiç boyut azaltamadığımı fark ettim ancak kodları da silmedim.\n",
    "- Aynı şekilde Single Unique Values yöntemini uygulamayı denedim ancak o yöntem ile de boyut azaltılamadı dolayısıyla o yöntem için hiç model kurmadım.\n",
    "- Veri setimde hiç eksik değer olmadığı için Missing Values boyut azaltma yöntemini uygulamayı denemedim.\n",
    "- Son olarak veri setine Low Importance Features ve Collinear Features yöntemlerini sırasıyla uyguladım. Bu iki yöntem uygulandıktan sonraki veri seti üzerinde modelleri tekrar kurdum.\n",
    "- Tüm boyut azaltma yöntemlerinin tek tek uygulanabileceği bir veri seti aradım ancak böyle bir veri seti bulamadım. Ben de bu veri seti üzerinde uygulayabileceğim yöntemleri uygulayıp yorumlamaya karar verdim.\n",
    "\n",
    "Boyut azaltma yöntemlerini uyguladıktan sonra model başarılarının çok düşük miktar da olsa düştüğünü gördüm. Veri setimdeki sütun sayısı çok daha fazla olsaydı model sonuçlarındaki değişimleri çok daha rahat gözlemleyebilirdim.\n",
    "Boyut sayısının azaltılması veri setinde bir miktar bilgi kaybına sebep olabilmektedir ancak model kurulurken harcanan süreyi de azaltmaktadır. Bazı durumlarda boyut azaltma yöntemleri sayesinde model başarısı artırılabilir ancak bu veri setinde model başarısının çok az miktarda azalan yönde değiştiğini gözlemledim.\n",
    "\n",
    "Bir tek Low Importance Features Yöntemi'nde Random Forest algoritmasının başarısı bir miktar artmış olarak göründü ancak Random Forest algoritmasını her çalıştırdığımda bu değer değişiyor. Bazı durumlarda model başarısının Low Importance Features Yöntemi uygulandıktan sonra düştüğü de oldu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
